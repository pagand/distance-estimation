{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"TrackR-CNN x BoxDist31 Video Outs","provenance":[],"collapsed_sections":["Lnh01Gfuk9YY"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mDUoS_DR4Xuv"},"source":["#Mount Google Drive\n","\n","This will allow the Colab machine to access Google Drive folders by mounting the drive on the machine. You will be asked to copy and paste an authentication code."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXq6fZ3ej_y0","executionInfo":{"status":"ok","timestamp":1619067399628,"user_tz":420,"elapsed":17728,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}},"outputId":"ee7aae08-64a8-4d0f-b46e-a4f0e60173e9"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C2rQLfyb4u6i"},"source":["# Change directory to allow imports\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LDw3ki24owK","executionInfo":{"status":"ok","timestamp":1619067401987,"user_tz":420,"elapsed":1109,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}},"outputId":"4f921730-d913-4f2d-9dbb-a4243a6adf80"},"source":["import os\n","os.chdir(\"/content/gdrive/My Drive/CMPT 419 720 Project/\")\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["'=2.0.1'\n"," BoxDist24_GT\n"," BoxDist24_TrackRCNN_Training\n"," BoxDist31_GT\n"," BoxDist31_TrackRCNN_Training\n"," cmpt419_mono_dept_esitmation_poster_v5.pdf\n","'CMPT419 Project Report.gdoc'\n"," FairMOT\n"," FairMOT.ipynb\n"," MDE_Experiments\n","'Milestone Report 1.gdoc'\n","'Milestone Report 2.gdoc'\n"," MonoDepthEstimation_v0.1\n"," output\n"," poster.gdoc\n"," References\n"," sceneflow\n","'synthetic data'\n"," testing\n"," trackr-cnn\n"," TrackRCNN\n"," TrackR-CNN\n"," trackr-cnn-v2\n","'TrackR-CNN x BoxDist24'\n","'TrackR-CNN x BoxDist31'\n","'TrackR-CNN x BoxDist31 Video Outs'\n"," training\n","'Weekly Briefings'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HJJ2wm_fm_4B"},"source":["##Import Libraries"]},{"cell_type":"code","metadata":{"id":"_jrJuMKinG5s","executionInfo":{"status":"ok","timestamp":1619067407430,"user_tz":420,"elapsed":4061,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["# import some common libraries\n","from google.colab.patches import cv2_imshow\n","from sklearn.metrics import jaccard_score\n","from PIL import Image, ImageDraw\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","import numpy as np\n","import datetime\n","import random\n","import json\n","import cv2\n","import csv\n","import os\n","\n","# import some common pytorch utilities\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch\n","\n","import pycocotools"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1iZccVU1Njox"},"source":["##Set Directory"]},{"cell_type":"code","metadata":{"id":"DMeSxbuANjTz","executionInfo":{"status":"ok","timestamp":1619067407431,"user_tz":420,"elapsed":2760,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["BASE_DIR = '/content/gdrive/My Drive/CMPT 419 720 Project/'\n","TESTING_DIR = os.path.join(BASE_DIR, 'testing')\n","OUTPUT_DIR = '{}/output'.format(BASE_DIR)\n","os.makedirs(OUTPUT_DIR, exist_ok=True)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gy-BLsXXMfTm"},"source":["#BoxDist31"]},{"cell_type":"markdown","metadata":{"id":"UYei8pZCvjbc"},"source":["##Network"]},{"cell_type":"markdown","metadata":{"id":"r8t-k_og2xC6"},"source":["Network Definition"]},{"cell_type":"code","metadata":{"id":"PyLIkJPZ2ymZ","executionInfo":{"status":"ok","timestamp":1619067416123,"user_tz":420,"elapsed":6043,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","class BBoxDistNet(nn.Module):\n","  def __init__(self):\n","    super(BBoxDistNet, self).__init__()\n","\n","    self.fc_net = nn.Sequential(\n","      nn.Linear(31, 18),\n","      nn.LayerNorm(18),\n","      nn.LeakyReLU(0.01, inplace=True),\n","      nn.Linear(18, 18),\n","      nn.LayerNorm(18),\n","      nn.LeakyReLU(0.01, inplace=True),\n","      nn.Linear(18, 3),\n","    )\n","  def forward(self, x):\n","    x = self.fc_net(x)\n","    return x\n","\n","net = BBoxDistNet().cuda()\n","\n","criterion = nn.L1Loss()"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XwermGAk25N2"},"source":["Load Pretrained Model"]},{"cell_type":"code","metadata":{"id":"RKNsqpcxtc3C","executionInfo":{"status":"ok","timestamp":1619067417077,"user_tz":420,"elapsed":935,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["net = torch.load(os.path.join(OUTPUT_DIR, 'bbox31_807_1633_58.pt')).cuda()"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YXP5XFJQ2xgn"},"source":["#Testing"]},{"cell_type":"code","metadata":{"id":"Qte7tnY26XuC","executionInfo":{"status":"ok","timestamp":1619067418008,"user_tz":420,"elapsed":502,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["set_names = ['0002', '0006', '0007', '0008', '0010', '0013', '0014', '0016', '0018']"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjXUpob3OKqo","executionInfo":{"status":"ok","timestamp":1619067418288,"user_tz":420,"elapsed":316,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["import math\n","\n","def dist(xyz):\n","    x = xyz[0]\n","    y = xyz[1]\n","    z = xyz[2]\n","    return math.sqrt(x**2+y**2+z**2)\n","\n","##predict displacement with forward euler\n","def dynamic_disp(v1, v2, a1, a2, t=0.1, h=0.001):\n","  ad = (a2-a1)/t\n","  d = 0\n","  v = v1\n","  a = a1\n","  for t in range(int(t/h)):\n","    a = a + h*ad\n","    v = v + h*a\n","    d += v*h + 0.5*a*h**2\n","  return d"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ntxgOoCB3RE_"},"source":["##Load Test GT Labels (Expected Outputs)"]},{"cell_type":"code","metadata":{"id":"p-Y-PvUY3RaY","executionInfo":{"status":"ok","timestamp":1619067419534,"user_tz":420,"elapsed":269,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["def load_gt_dists(set_names):\n","  gt_len = 0\n","  annotations = {}\n","  kitti_anno_dir = os.path.join(TESTING_DIR, 'label_02')\n","  tracking_anno_dir = os.path.join(TESTING_DIR, 'tracking_data/segmentations')\n","\n","  for set_name in set_names:\n","    kitti_anno_file = os.path.join(kitti_anno_dir, set_name+'.txt')\n","    tracking_anno_file = os.path.join(tracking_anno_dir, set_name+'.txt')\n","    records = {}\n","\n","    tracking_anno = open(tracking_anno_file, 'r')\n","    tracking_lines = tracking_anno.readlines()\n","    line = tracking_lines[0]\n","    e = line.split(' ')\n","    height = int(e[3])\n","    width = int(e[4])\n","\n","#Load Kitti Annotations\n","    kitti_anno = open(kitti_anno_file, 'r')\n","    kitti_lines = kitti_anno.readlines()\n","    for line in kitti_lines:\n","      e = line.split(' ')\n","      class_name = e[2]\n","      trunc = float(e[3])\n","      if (class_name != 'Car' and class_name != 'Pedestrian') or trunc > 0: #data exclusion\n","        continue\n","      frame = int(e[0])\n","      obj_id = int(e[1])\n","      if frame not in records.keys():\n","        records[frame] = {}\n","      if obj_id not in records[frame].keys():\n","        records[frame][obj_id] = {}\n","      records[frame][obj_id] = {\n","          'bbox': [float(e[6])/width, float(e[7])/height, float(e[8])/width, float(e[9])/height],\n","          'target': torch.from_numpy(np.array([float(e[13]), float(e[14]), float(e[15])])),\n","          'centre': [((float(e[6])+(float(e[8])-float(e[6]))/2)-(width/2))/width, ((float(e[7])+(float(e[9])-float(e[7]))/2)-(height/2))/height]\n","      }\n","      gt_len += 1\n","    annotations[set_name] = records\n","  print('GT has %d object instances' %(gt_len))\n","  return annotations"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"JEueOp7HNUBb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619067427165,"user_tz":420,"elapsed":5970,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}},"outputId":"4f0cd570-11b7-4106-bd9a-612f761fd175"},"source":["gt_obj_dists = load_gt_dists(set_names)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["GT has 10846 object instances\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g-FoaP203GsK"},"source":["##Load Track-RCNN Detections & Frame IMU Data (Inputs)"]},{"cell_type":"code","metadata":{"id":"hYIXMks53JW-","executionInfo":{"status":"ok","timestamp":1619067427165,"user_tz":420,"elapsed":4625,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["from pycocotools import mask as cocomask\n","\n","def load_track_imu(set_names):\n","  pred_len = 0\n","  annotations = {}\n","  tracking_anno_dir = os.path.join(TESTING_DIR, 'tracking_data/segmentations')\n","  detection_anno_dir = os.path.join(TESTING_DIR, 'tracking_data/detections')\n","  gps_anno_dir = os.path.join(TESTING_DIR, 'oxts')\n","\n","  for set_name in set_names:\n","    tracking_anno_file = os.path.join(tracking_anno_dir, set_name+'.txt')\n","    detection_anno_file = os.path.join(detection_anno_dir, set_name+'.txt')\n","    gps_anno_file = os.path.join(gps_anno_dir, set_name+'.txt')\n","    records = {}\n","\n","#Load GPS Annotations\n","    gps_anno = open(gps_anno_file, 'r')\n","    gps_lines = gps_anno.readlines()\n","    gps = {}\n","    for frame, line in enumerate(gps_lines):\n","      e = line.split(' ')\n","      v = [float(e[8]), float(e[9]), float(e[10])]\n","      a = [float(e[11]), float(e[12]), float(e[13])]\n","      gps[frame] = {\n","          'v': v,\n","          'a': a,\n","      }\n","    \n","    tracking_anno = open(tracking_anno_file, 'r')\n","    tracking_lines = tracking_anno.readlines()\n","    for line in tracking_lines:\n","      e = line.split(' ')\n","      frame = int(e[0])\n","      if frame not in gps.keys():\n","        continue\n","      class_id = int(e[2])\n","      if class_id == 1:\n","        class_id = 0\n","      elif class_id == 2:\n","        class_id = 3\n","      obj_id = int(e[1])-1\n","      if frame not in records.keys():\n","        records[frame] = {}\n","        records[frame]['objs'] = {}\n","      height = int(e[3])\n","      width = int(e[4])\n","      records[frame]['height'] = height\n","      records[frame]['width'] = width\n","      records[frame]['v'] = gps[frame]['v']\n","      records[frame]['a'] = gps[frame]['a']\n","      records[frame]['frame'] = frame\n","      rle_obj = {\n","          'counts': e[5],\n","          'size': [height, width]\n","      }\n","      #bbox = cocomask.toBbox(rle_obj) #outputs XYWH\n","      if obj_id not in records[frame]['objs'].keys():\n","        records[frame]['objs'][obj_id] = {}\n","      #records[frame]['objs'][obj_id]['bbox'] = [bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]]\n","      records[frame]['objs'][obj_id]['rle'] = e[5].rstrip()\n","      records[frame]['objs'][obj_id]['class_id'] = class_id\n","\n","    detection_anno = open(detection_anno_file, 'r')\n","    detection_lines = detection_anno.readlines()\n","    for line in detection_lines:\n","      e = line.split(' ')\n","      frame = int(e[0])\n","      confidence = float(e[5])\n","      if frame not in records.keys():\n","        continue\n","      bbox = [float(e[1]), float(e[2]), float(e[3]), float(e[4])]\n","      if 0.0 in bbox or width in bbox or height in bbox:# or confidence < 0.5 :\n","        continue\n","      rle = e[9].rstrip()\n","      for obj_id in records[frame]['objs'].keys():\n","        if records[frame]['objs'][obj_id]['rle'] == rle:\n","          records[frame]['objs'][obj_id]['bbox'] = bbox\n","          break\n","        pred_len += 1;\n","\n","    annotations[set_name] = records\n","  \n","  print('TrackR-CNN has %d object instances' %(pred_len))\n","  return annotations\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"NR-ya73uYG8U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619067436652,"user_tz":420,"elapsed":6778,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}},"outputId":"8bd25da7-390d-4a22-8db4-bcd98ba1a27c"},"source":["tracking_imu_data = load_track_imu(set_names)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["TrackR-CNN has 169695 object instances\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZHpzPc0HYbg4"},"source":["##Construct Model Inputs\n"]},{"cell_type":"code","metadata":{"id":"fAdUj8CXYd9k","executionInfo":{"status":"ok","timestamp":1619067445069,"user_tz":420,"elapsed":345,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["def make_input(frame1, frame2, delta=1):\n","  height = frame1['height']\n","  width = frame1['width']\n","  img_center = [width/2, height/2]\n","  bbox1 = [frame1['bbox'][0]/width, frame1['bbox'][1]/height, frame1['bbox'][2]/width, frame1['bbox'][3]/height]\n","  bbox2 = [frame2['bbox'][0]/width, frame2['bbox'][1]/height, frame2['bbox'][2]/width, frame2['bbox'][3]/height]\n","  xd = -dynamic_disp(frame1['v'][1], frame2['v'][1], frame1['a'][1], frame2['a'][1], delta*0.1)\n","  yd = -dynamic_disp(frame1['v'][2], frame2['v'][2], frame1['a'][2], frame2['a'][2], delta*0.1)\n","  zd = dynamic_disp(frame1['v'][0], frame2['v'][0], frame1['a'][0], frame2['a'][0], delta*0.1)\n","  disp = [xd, yd, zd]\n","  bbox1 = [frame1['bbox'][0]/width, frame1['bbox'][1]/height, frame1['bbox'][2]/width, frame1['bbox'][3]/height]\n","  bbox2 = [frame2['bbox'][0]/width, frame2['bbox'][1]/height, frame2['bbox'][2]/width, frame2['bbox'][3]/height]\n","  w1 = bbox1[2] - bbox1[0]\n","  w2 = bbox2[2] - bbox2[0]\n","  h1 = bbox1[3] - bbox1[1]\n","  h2 = bbox2[3] - bbox2[1]\n","  a1 = w1*h1\n","  a2 = w2*h2\n","  c1 = [(frame1['bbox'][0]+(w1/2)-img_center[0])/(width/2), (frame1['bbox'][1]+(h1/2)-img_center[1])/(height/2)]\n","  c2 = [(frame2['bbox'][0]+(w2/2)-img_center[0])/(width/2), (frame2['bbox'][1]+(h2/2)-img_center[1])/(height/2)]\n","  class_id = frame1['class_id']\n","  id_vec = [0, 0, 0, 0, 0, 0, 0]\n","  id_vec[class_id] = 1\n","  input = torch.from_numpy(np.array(id_vec + bbox1 + bbox2 + disp + [w1, w2, h1, h2, a1, a2] + c1 + c2 + [w2/w1, h2/h1, a2/a1]).astype(np.float32)).cuda()\n","  return input"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A_x0pRmf3Mye"},"source":["##Measure Accuracy"]},{"cell_type":"code","metadata":{"id":"h4KKc1Q5p2iB"},"source":["#net = torch.load(os.path.join(OUTPUT_DIR, 'bbox31_807_1633_58.pt')).cuda()\n","net = torch.load(os.path.join(OUTPUT_DIR, 'bbox31_trackrcnn.pt')).cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lnh01Gfuk9YY"},"source":["###Deprecated Code"]},{"cell_type":"code","metadata":{"id":"nTc4rcFblAG9"},"source":["def pt_dists_2D(p0, pts):\n","  dists = []\n","  for pt in pts:\n","    dists.append(math.sqrt((p0[0]-pt[0])**2+(p0[1]-pt[1])**2))\n","  return dists\n","\n","def bbox_overlap_ratio(bbox0, bboxs):\n","  ratios = []\n","  area0 = (bbox0[2]-bbox0[0]) * (bbox0[3]-bbox0[1])\n","  for bbox in bboxs:\n","    x_left = max(bbox0[0], bbox[0])\n","    y_top = max(bbox0[1], bbox[1])\n","    x_right = min(bbox0[2], bbox[2])\n","    y_bottom = min(bbox0[3], bbox[3])\n","    if x_right < x_left or y_bottom < y_top:\n","      iou = 0.0\n","      ratios.append(iou)\n","    else:\n","      intersection_area = (x_right - x_left) * (y_bottom - y_top)\n","      bb1_area = (bbox0[2] - bbox0[0]) * (bbox0[3] - bbox0[1])\n","      bb2_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n","      iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n","      ratios.append(iou)\n","\n","  return ratios\n","\n","def align_input_to_gt(inputs, gts):\n","  input_cs = []\n","  gt_cs = []\n","  for input in inputs:\n","    numpy_input = input.detach().cpu().numpy()\n","    input_c = [numpy_input[26], numpy_input[27]]\n","    input_cs.append(input_c)\n","  for obj_id in gts.keys():\n","    gt_c = gts[obj_id]['centre']\n","    gt_cs.append(gt_c)\n","  \n","  dist_table = []\n","  for gt_c in gt_cs:\n","    dists = pt_dists_2D(gt_c, input_cs)\n","    dist_table.append(dists)\n","  dist_table = np.array(dist_table)\n","\n","  alignments = [-1]*len(gts)\n","\n","  input_mins = []\n","  gt_mins = []\n","  for i in range(len(inputs)):\n","    input_mins.append(np.argmin(dist_table[:, i]))\n","  for i in range(len(gts)):\n","    gt_mins.append(np.argmin(dist_table[i, :]))\n","\n","  for i, gt_min in enumerate(gt_mins):\n","    if input_mins[gt_min] == i:\n","      alignments[i] = gt_min\n","\n","  return alignments\n","\n","\n","def align_input_to_gt(inputs, gts):\n","  input_bboxs = []\n","  gt_bboxs = []\n","  for input in inputs:\n","    numpy_input = input.detach().cpu().numpy()\n","    input_bbox = [numpy_input[11], numpy_input[12], numpy_input[13], numpy_input[14]]\n","    input_bboxs.append(input_bbox)\n","  for obj_id in gts.keys():\n","    gt_bbox = gts[obj_id]['bbox']\n","    gt_bboxs.append(gt_bbox)\n","  \n","  ratio_table = []\n","  for gt_bbox in gt_bboxs:\n","    ratios = pt_dists_2D(gt_bbox, input_bboxs)\n","    ratio_table.append(ratios)\n","  ratio_table = np.array(ratio_table)\n","\n","  alignments = [-1]*len(gts)\n","\n","  input_maxs = []\n","  gt_maxs = []\n","  for i in range(len(inputs)):\n","    if np.max(ratio_table[:, i]) == 0:\n","      input_maxs.append(-2)\n","    else:\n","      input_maxs.append(np.argmax(ratio_table[:, i]))\n","  for i in range(len(gts)):\n","    if np.max(ratio_table[i, :]) == 0:\n","      gt_maxs.append(-2)\n","    else:\n","      gt_maxs.append(np.argmax(ratio_table[i, :]))\n","    \n","  for i, gt_max in enumerate(gt_maxs):\n","    if input_maxs[gt_max] == i:\n","      alignments[i] = gt_max\n","\n","  return alignments"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PWxYpkQWlAXf"},"source":["###Pred/Target Alignment"]},{"cell_type":"code","metadata":{"id":"OAJHVQsWii8_","executionInfo":{"status":"ok","timestamp":1619067449775,"user_tz":420,"elapsed":285,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["def bbox_overlap_ratio(bbox0, bboxs):\n","  ratios = []\n","  area0 = (bbox0[2]-bbox0[0]) * (bbox0[3]-bbox0[1])\n","  for bbox in bboxs:\n","    x_left = max(bbox0[0], bbox[0])\n","    y_top = max(bbox0[1], bbox[1])\n","    x_right = min(bbox0[2], bbox[2])\n","    y_bottom = min(bbox0[3], bbox[3])\n","    if x_right < x_left or y_bottom < y_top:\n","      iou = 0.0\n","      ratios.append(iou)\n","    else:\n","      intersection_area = (x_right - x_left) * (y_bottom - y_top)\n","      bb1_area = (bbox0[2] - bbox0[0]) * (bbox0[3] - bbox0[1])\n","      bb2_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n","      iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n","      ratios.append(iou)\n","\n","  return ratios\n","\n","def align_input_to_gt(inputs, gts):\n","  input_bboxs = []\n","  gt_bboxs = []\n","  for input in inputs:\n","    numpy_input = input.detach().cpu().numpy()\n","    input_bbox = [numpy_input[11], numpy_input[12], numpy_input[13], numpy_input[14]]\n","    input_bboxs.append(input_bbox)\n","  for obj_id in gts.keys():\n","    gt_bbox = gts[obj_id]['bbox']\n","    gt_bboxs.append(gt_bbox)\n","  \n","  ratio_table = []\n","  for gt_bbox in gt_bboxs:\n","    ratios = bbox_overlap_ratio(gt_bbox, input_bboxs)\n","    ratio_table.append(ratios)\n","  ratio_table = np.array(ratio_table)\n","\n","  alignments = [-1]*len(gts)\n","\n","  gt_maxs = []\n","  for i in range(len(gts)):\n","    gt_maxs.append(np.argmax(ratio_table[i, :]))\n","  input_maxs = []\n","  for i in range(len(inputs)):\n","    input_maxs.append(np.argmax(ratio_table[:, i]))\n","\n","  for me, want in enumerate(gt_maxs):\n","    if input_maxs[want] == me and ratio_table[me, want] > 0.0:\n","      alignments[me] = want\n","\n","  return alignments"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UYu2LPhukhA5"},"source":["###Measure"]},{"cell_type":"code","metadata":{"id":"hMC7gMzY26Gc","executionInfo":{"status":"ok","timestamp":1619068031120,"user_tz":420,"elapsed":6116,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["frame_records = {}\n","output_records = []\n","target_records = []\n","n = 0\n","abs_errors = []\n","rel_errors = []\n","preds = []\n","dists = []\n","net.eval()\n","for set_name in set_names:\n","  frame_records[set_name] = {}\n","  prev_data = {}\n","  for frame in gt_obj_dists[set_name].keys():\n","    frame_records[set_name][frame] = {\n","        'bboxs': [],\n","        'preds': [],\n","        'dists': [],\n","    }\n","    if frame not in tracking_imu_data[set_name].keys():\n","      continue\n","    inputs = []\n","    for obj_id in tracking_imu_data[set_name][frame]['objs']:\n","      this_frame = tracking_imu_data[set_name][frame]\n","      if obj_id in prev_data.keys() and 'bbox' in this_frame['objs'][obj_id].keys():\n","        last_frame = prev_data[obj_id]\n","        if 'bbox' in last_frame['objs'][obj_id].keys():\n","          frame1 = {\n","              'v': last_frame['v'],\n","              'a': last_frame['a'],\n","              'bbox': last_frame['objs'][obj_id]['bbox'],\n","              'class_id': last_frame['objs'][obj_id]['class_id'],\n","              'height': last_frame['height'], \n","              'width': last_frame['width'],\n","          }\n","          frame2 = {\n","              'v': this_frame['v'],\n","              'a': this_frame['a'],\n","              'bbox': this_frame['objs'][obj_id]['bbox'],\n","              'class_id': this_frame['objs'][obj_id]['class_id'],\n","          }\n","          delta = this_frame['frame'] - last_frame['frame']\n","          input = make_input(frame1, frame2, delta)\n","          inputs.append(input)\n","      prev_data[obj_id] = this_frame\n","\n","    if len(inputs) == 0:\n","      continue\n","\n","    outputs = []\n","    with torch.no_grad():\n","      for input in inputs:\n","        output = net(input).detach().cpu()\n","        outputs.append(output)\n","    \n","    frame_gt = gt_obj_dists[set_name][frame]\n","\n","    alignment = align_input_to_gt(inputs, frame_gt)\n","\n","    targets = []\n","\n","    for obj_id in frame_gt.keys():\n","      targets.append(frame_gt[obj_id]['target'])\n","    \n","    for t, o in enumerate(alignment):\n","      if o == -1:\n","        continue\n","      output = outputs[o]\n","      target = targets[t]\n","      input = inputs[o]\n","      numpy_input = input.detach().cpu().numpy()\n","      input_bbox = [numpy_input[11], numpy_input[12], numpy_input[13], numpy_input[14]]\n","      frame_records[set_name][frame]['bboxs'].append(input_bbox)\n","      frame_records[set_name][frame]['preds'].append(dist(output))\n","      frame_records[set_name][frame]['dists'].append(dist(target))\n","      n += 1"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySqqIVxQ9gLD","executionInfo":{"status":"ok","timestamp":1619067803930,"user_tz":420,"elapsed":321,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}},"outputId":"009891a0-6fba-425e-ecc0-882bff37a189"},"source":["print(n)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["6702\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"at7VU87d5s8x"},"source":["#Video"]},{"cell_type":"code","metadata":{"id":"8wZEMA-85uhH","executionInfo":{"status":"ok","timestamp":1619069688763,"user_tz":420,"elapsed":276,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}}},"source":["def make_videos(set_name):\n","  img_dir = os.path.join(os.path.join(TESTING_DIR, 'image_02'), set_name)\n","  height = 374\n","  width = 1238\n","  img_center = [width/2, height/2]\n","  vid_writer = cv2.VideoWriter(filename=OUTPUT_DIR+\"/track-rcnnxBoxdist31_\"+set_name+\".avi\",  #Provide a file to write the video to\n","  fourcc=cv2.VideoWriter_fourcc('p', 'n', 'g', ' '),            #Use whichever codec works for you...\n","  fps=10,                                        #How many frames do you want to display per second in your video?\n","  frameSize=(width, height))   \n","\n","  #prev data\n","  data = {}\n","\n","  net.eval()\n","  with torch.no_grad():\n","      for frame in frame_records[set_name].keys():\n","        img_name = '000000'\n","        img_name = img_name[0:6-len(str(frame))] + str(frame)\n","        img = cv2.imread(os.path.join(img_dir, img_name+'.png'))\n","        print(img.shape)\n","        bboxes = frame_records[set_name][frame]['bboxs']\n","        preds = frame_records[set_name][frame]['preds']\n","        dists = frame_records[set_name][frame]['dists']\n","        for i, bbox in enumerate(bboxes):\n","          #draw boxes\n","          label = '%.f | %.2f' %(preds[i], dists[i])\n","          x1 = int(bbox[0]*width)\n","          x2 = int(bbox[2]*width)\n","          y1 = int(bbox[1]*height)\n","          y2 = int(bbox[3]*height)\n","          cv2.rectangle(img,(x1,y1),(x2,y2),(0,200,0),1)\n","          labelSize=cv2.getTextSize(label,cv2.FONT_HERSHEY_SIMPLEX,0.5,2)\n","          _x1 = x1\n","          _y1 = y1#+int(labelSize[0][1]/2)\n","          _x2 = _x1+labelSize[0][0]\n","          _y2 = y1-int(labelSize[0][1])\n","          cv2.rectangle(img,(_x1,_y1),(_x2,_y2),(0,200,0),cv2.FILLED)\n","          cv2.putText(img,label,(x1,y1),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,0,255),1)\n","          #write to video\n","        vid_writer.write(img)\n","\n","  vid_writer.release()"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NM2_nUqQ8Zao","executionInfo":{"status":"ok","timestamp":1619069829271,"user_tz":420,"elapsed":138684,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}},"outputId":"2627432a-8352-4920-b1bb-316d38d59615"},"source":["make_videos('0018')"],"execution_count":50,"outputs":[{"output_type":"stream","text":["(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n","(374, 1238, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"LAscGta38o61","executionInfo":{"status":"error","timestamp":1619067576539,"user_tz":420,"elapsed":527,"user":{"displayName":"Mike Caxi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOjDlmTeqhOSIY-cGDXp3DYxN0SWu0zE4dCAPV=s64","userId":"02290132101536635757"}},"outputId":"ecadc27c-b9e6-4784-a037-c6f234f11ccd"},"source":["vid_writer.release()"],"execution_count":24,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-ee0697e569d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvid_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'vid_writer' is not defined"]}]}]}